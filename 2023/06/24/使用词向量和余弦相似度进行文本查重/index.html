<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.15.1">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://fastly.jsdelivr.net'>
  <link rel="preconnect" href="https://fastly.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>Eumendies</title>

  
    <meta name="description" content="Word2vec是一种用于自然语言处理的算法，它可以将文本中的单词表示为高维向量，这些向量可以被用来计算单词之间的相似度。而余弦相似度是一种用于计算向量之间相似度的度量方法，本文使用word2vec和余弦相似度结合的方法来进行文本的查重。">
<meta property="og:type" content="article">
<meta property="og:title" content="使用词向量和余弦相似度进行文本查重">
<meta property="og:url" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/index.html">
<meta property="og:site_name" content="Eumendies">
<meta property="og:description" content="Word2vec是一种用于自然语言处理的算法，它可以将文本中的单词表示为高维向量，这些向量可以被用来计算单词之间的相似度。而余弦相似度是一种用于计算向量之间相似度的度量方法，本文使用word2vec和余弦相似度结合的方法来进行文本的查重。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/basic.png">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/architecture.png">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/CBOW.png">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/Skip-gram.png">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/window.gif">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/pair.png">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/multiply.png">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/sentence.png">
<meta property="og:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/detect.png">
<meta property="article:published_time" content="2023-06-24T06:34:42.000Z">
<meta property="article:modified_time" content="2023-06-24T14:52:00.832Z">
<meta property="article:author" content="Eumendies">
<meta property="article:tag" content="NLP">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://eumendies.github.io/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/basic.png">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  
    <link rel="shortcut icon" href="/images/logo.jpg">
  

  

  


  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header">

<div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="/images/logo.jpg" onerror="javascript:this.classList.add('error');this.src='https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">Eumendies</div></a></div>


<nav class="menu dis-select"><a class="nav-item active" href="/">文章</a><a class="nav-item" href="/friends/">友链</a><a class="nav-item" href="/about/">关于</a></nav>
</header>


<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">使用词向量和余弦相似度进行文本查重</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%9F%BA%E6%9C%AC%E6%80%9D%E6%83%B3"><span class="toc-text">1.1 基本思想</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84%E4%B8%8E%E4%B8%A4%E7%A7%8D%E6%A8%A1%E5%9E%8B"><span class="toc-text">1.2 网络结构与两种模型</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AE%AD%E7%BB%83%E8%BF%87%E7%A8%8B"><span class="toc-text">1.3 训练过程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%A5%E5%AD%90%E7%9A%84%E5%90%91%E9%87%8F%E8%A1%A8%E7%A4%BA"><span class="toc-text">3.1 句子的向量表示</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%A3%80%E6%B5%8B"><span class="toc-text">3.2 检测</span></a></li></ol></div></div></div>




</div>


    </aside>
    <div class='l_main'>
      

      

    
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
            inlineMath: [ ['$','$'], ["\\(","\\)"] ],
            processEscapes: true
          }
        });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
            tex2jax: {
              skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
            }
          });
      </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
              var all = MathJax.Hub.getAllJax(), i;
              for(i=0; i < all.length; i += 1) {
                  all[i].SourceElement().parentNode.className += ' has-jax';
              }
          });
      </script>

    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>




<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/deep-learning/">deep-learning</a></div><div id="post-meta">发布于&nbsp;<time datetime="2023-06-24T06:34:42.000Z">2023-06-24</time></div></div>

<article class='content md post'>
<h1 class="article-title"><span>使用词向量和余弦相似度进行文本查重</span></h1>
<p>Word2vec是一种用于自然语言处理的算法，它可以将文本中的单词表示为高维向量，这些向量可以被用来计算单词之间的相似度。而余弦相似度是一种用于计算向量之间相似度的度量方法，本文使用word2vec和余弦相似度结合的方法来进行文本的查重。</p>
<span id="more"></span>
<h1 id="word2vec">1. Word2Vec</h1>
<h2 id="基本思想">1.1 基本思想</h2>
<p>word2vec是一种基于神经网络的自然语言处理算法，通过学习大量文本语料库中单词的上下文信息，将单词转换为固定长度的高维向量。
<span class="math display">\[
word \Longrightarrow \overbrace{[ \,\,
0.881,\,0.126,\,0.753,\,0.294,\,…\,,\,0.745\,\,]}^{embedding\,\,length}
\]</span>
word2vec的基本思想是根据单词的上下文来学习单词的语义，这就意味着那些经常出现在相同上下文中的单词，映射到向量空间后其欧几里得距离会比较相近。比如给神经网络输入两个句子：He
loved the <strong>big</strong> old house. He loved the
<strong>large</strong> old house.
由于big和large出现在了相似的上下文中，因此神经网络会认为它们具有相近的语义，然后将它们映射到同一片向量空间中，当上下文相似的句子出现得越多，两个单词在向量空间中就会越接近。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/basic.png"></p>
<blockquote>
<p>图片仅作示例，实际上的词向量维度要远大于3</p>
</blockquote>
<h2 id="网络结构与两种模型">1.2 网络结构与两种模型</h2>
<p>word2vec的网络结构相当简单，其仅仅包含输入层、一个隐藏层和输出层，我们需要的词向量可以从输入层到隐藏层的权重矩阵中提取，或者从隐藏层到输出层的权重矩阵中提取，具体训练过程下文描述。</p>
<figure>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/architecture.png" alt="architecture">
<figcaption aria-hidden="true">architecture</figcaption>
</figure>
<p>word2vec有两种不同的模型，一种是Continuous Bag-of-Words
Model(CBOW)，一种是Contiguous Skip-gram Model(Skip-gram)。</p>
<p>两种模型的区别主要在于输入和输出的形式。对于CBOW模型，其任务是根据上下文来预测当前出现的单词，相当于选词填空。首先从句子中选择一个词作为目标值，然后将指定长度的上下文作为输入来训练神经网络。比如：<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/CBOW.png" alt="CBOW"></p>
<p>而Skip-gram模型则相反，其要求输入一个词，然后根据这个词来预测指定长度的上下文。</p>
<figure>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/Skip-gram.png" alt="skip-gram">
<figcaption aria-hidden="true">skip-gram</figcaption>
</figure>
<h2 id="训练过程">1.3 训练过程</h2>
<p>word2vec的输入向量和输出向量都用one-hot的形式给出，所谓one-hot向量，即向量中仅有一个元素为1，而剩余元素皆为0的向量。首先我们要确定我们字典(所有出现在训练集和测试集中的词的集合)的大小，然后给每一个词一个唯一的索引。则所有词的one-hot向量长度固定为字典大小，一个词的one-hot向量即索引处为1，其余处为0的向量。比如：
<span class="math display">\[
dict.length == 5\\
dict[2] = &#39;big&#39;\\
big的one-hot向量:\,[0,0,1,0,0]
\]</span> 本项目使用的是CBOW模型，下面以CBOW模型为例来进行说明。</p>
<p>首先需要遍历整个训练集，找出所有出现的不同的字，并且给每一个字一个唯一的id。</p>
<p>然后在训练集中取出一段文本，使用一个滑动窗口(以大小为3的窗口为例)来取得一个个词袋，取中间的字作为目标值，剩下的字作为输入值。</p>
<figure>
<img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/window.gif" alt="window">
<figcaption aria-hidden="true">window</figcaption>
</figure>
<p>对于每一个词袋，将其拆成输入字与目标字的一对，输入字和目标字都转换成one-hot向量，故训练时是一个一个字地输入到网络当中。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/pair.png"></p>
<p>处理完训练集中所有文本后得到所有的输入-目标对，就可以进行训练，设字典大小为vocab_size，要获得的词向量的维数为embedding_size，则输入张量的形状为[batch_size,
vocab_size]，输出张量的形状为[batch_size,
vocab_size]，可以得到网络结构如下(pytorch)：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VocabEmbedding</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VocabEmbedding, self).__init__()</span><br><span class="line">        self.W = nn.Linear(vocab_size, embedding_size, bias=<span class="literal">False</span>)</span><br><span class="line">        self.WT = nn.Linear(embedding_size, vocab_size, bias=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line">        hidden_layer = self.W(X)</span><br><span class="line">        output_layer = self.WT(hidden_layer)</span><br><span class="line">        <span class="keyword">return</span> output_layer</span><br></pre></td></tr></table></figure>
<p>权重矩阵的形状为[vocab_size,
embedding_size]，当一个one-hot向量与其相乘时，因为one-hot向量中只有一个元素为1，所以计算结果实际上只与权重矩阵中的一行有关，计算输出值和目标值的误差后进行反向传播，也只有权重矩阵中的一行会被更新，因为其他行对输出值没有贡献。以vocab_size=5,
embedding_size=7为例：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/multiply.png"></p>
<u>训练完毕后，我们只需在权重矩阵中按词的id取出相应的行向量即可作为每个词的向量。</u>
<h1 id="余弦相似度">2. 余弦相似度</h1>
<p>余弦相似度使用两个向量之间的夹角来衡量两个向量之间的相似程度，其计算公式如下：
<span class="math display">\[
similarity = cos\theta = \frac{\vec{x}·\vec{y}}{||x||\,·\,||y||}
\]</span>
欧氏距离更加注重两个向量在数值上的差异，余弦相似度则注重两个向量在方向上的差异。</p>
<h1 id="文本查重">3. 文本查重</h1>
<h2 id="句子的向量表示">3.1 句子的向量表示</h2>
<p>通过word2vec，我们已经得到了每个字的向量表示，要得到每个句子的向量表示，我选择了直接将一个句子中所有字的向量简单加和，这样每个句子的向量都具有相同的长度，更加方便处理。</p>
<p>但是，这种做法丢失了字与字之间的时序信息，导致具有相同字但顺序不同的句子也被检测为相似，比如“国立武汉大学”和“学大汉武立国”在这种方法下会被认定为是完全相同的句子。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/sentence.png"></p>
<h2 id="检测">3.2 检测</h2>
<p>将一篇文章分句后，再获得每个句子的向量，将这些向量组合成一个矩阵，这个矩阵就代表了这篇文章的内容。在组合成矩阵之前先将句子向量进行单位化，这样的话将两个文章的矩阵直接相乘就可以计算处两篇文章所有句子两两之间的余弦相似度。两篇文章的矩阵形状分别为[num_sentences,
embedding_size]，[embedding_size, num_sentence]。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2023/06/24/%E4%BD%BF%E7%94%A8%E8%AF%8D%E5%90%91%E9%87%8F%E5%92%8C%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E5%BA%A6%E8%BF%9B%E8%A1%8C%E6%96%87%E6%9C%AC%E6%9F%A5%E9%87%8D/detect.png"></p>
<h1 id="仓库地址">4. 仓库地址</h1>
<p><a target="_blank" rel="noopener" href="https://github.com/eumendies/plagiarism_detection">eumendies/plagiarism_detection:
plagiarism detection with word2vec and cosine similarity
(github.com)</a></p>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用<a
target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享
4.0 国际</a>许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/04/07/%E7%AE%80/">简</a></div></section></div>






  <div class='related-wrap md reveal' id="comments">
    <div class='cmt-title cap theme'>
      快来参与讨论吧
    </div>
    <div class='cmt-body waline'>
      

<div id="waline_container" class="waline_thread"><svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/"><span class="citation"
data-cites="Eumendies">@Eumendies</span></a> 使用 <a
target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a>
主题创建。 本博客所有文章除特别声明外，均采用 <a
target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA
4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.15.1';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.15.1';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://fastly.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js'
  };

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://fastly.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://fastly.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://fastly.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function load_comment(){
    if(!document.getElementById("waline_container"))return;
    stellar.loadCSS('https://unpkg.com/@waline/client@v2/dist/waline.css');
    stellar.loadScript('https://unpkg.com/@waline/client@v2/dist/waline.js', {defer:true}).then(function () {
      const el = document.getElementById("waline_container");
      var path = el.getAttribute('comment_id');
      if (!path) {
        path = decodeURI(window.location.pathname);
      }
      Waline.init(Object.assign({"js":"https://unpkg.com/@waline/client@v2/dist/waline.js","css":"https://unpkg.com/@waline/client@v2/dist/waline.css","serverURL":"https://example.eumendies.me/","commentCount":false,"pageview":false,"emoji":["https://unpkg.com/@waline/emojis@1.1.0/qq","https://unpkg.com/@waline/emojis@1.1.0/tieba","https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs"],"meta":["昵称","邮箱","nick","mail"],"requiredMeta":["nick"],"lang":"zh-CN","wordLimit":0,"pageSize":10,"locale":{"placeholder":"快来发表你的看法吧（不用登录也能评论）"},"login":"enable"}, {
        el: '#waline_container',
        path: path,
      }));
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
    console.log('DOM fully loaded and parsed');
    load_comment();
  });

</script>




<!-- inject -->


  </div>
</body>
</html>
