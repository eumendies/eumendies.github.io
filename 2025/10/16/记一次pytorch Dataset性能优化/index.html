<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.3.0">
  <meta name="hexo-theme" content="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.15.1">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://fastly.jsdelivr.net'>
  <link rel="preconnect" href="https://fastly.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  
  <title>Eumendies</title>

  
    <meta name="description" content="最近跑模型的时候发现GPU利用率奇低，基本维持在百分之十几左右，还会间歇性掉到0，导致训练60K个iteration就需要接近3天的时间，而官方论文的训练总数是整整600K iteration，这就意味着如果我要跑一次全量训练起码要30天，这肯定是无法接受的，因此需要定位问题再进行性能优化。">
<meta property="og:type" content="article">
<meta property="og:title" content="记一次pytorch Dataset性能优化">
<meta property="og:url" content="https://eumendies.github.io/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/index.html">
<meta property="og:site_name" content="Eumendies">
<meta property="og:description" content="最近跑模型的时候发现GPU利用率奇低，基本维持在百分之十几左右，还会间歇性掉到0，导致训练60K个iteration就需要接近3天的时间，而官方论文的训练总数是整整600K iteration，这就意味着如果我要跑一次全量训练起码要30天，这肯定是无法接受的，因此需要定位问题再进行性能优化。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://eumendies.github.io/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/tensorboard.png">
<meta property="og:image" content="https://eumendies.github.io/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/perfetto.png">
<meta property="og:image" content="https://eumendies.github.io/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/perfetto2.png">
<meta property="article:published_time" content="2025-10-16T03:20:09.000Z">
<meta property="article:modified_time" content="2025-10-16T07:24:44.627Z">
<meta property="article:author" content="Eumendies">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://eumendies.github.io/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/tensorboard.png">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  
    <link rel="shortcut icon" href="/images/logo.jpg">
  

  

  


  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    

  

<header class="header">

<div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="/images/logo.jpg" onerror="javascript:this.classList.add('error');this.src='https://fastly.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main" ff="title">Eumendies</div></a></div>


<nav class="menu dis-select"><a class="nav-item active" href="/">文章</a><a class="nav-item" href="/friends/">友链</a><a class="nav-item" href="/about/">关于</a></nav>
</header>


<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">记一次pytorch Dataset性能优化</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%BD%AC%E6%8D%A2%E4%B8%BAlmdb%E6%95%B0%E6%8D%AE%E5%BA%93"><span class="toc-text">2.1 转换为LMDB数据库</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#div_"><span class="toc-text">2.2 div_()</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%A1%BA%E5%BA%8F%E8%AF%BB"><span class="toc-text">2.3 顺序读</span></a></li></ol></div></div></div>




</div>


    </aside>
    <div class='l_main'>
      

      


<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/deep-learning/">deep-learning</a></div><div id="post-meta">发布于&nbsp;<time datetime="2025-10-16T03:20:09.000Z">2025-10-16</time></div></div>

<article class='content md post'>
<h1 class="article-title"><span>记一次pytorch Dataset性能优化</span></h1>
<p>最近跑模型的时候发现GPU利用率奇低，基本维持在百分之十几左右，还会间歇性掉到0，导致训练60K个iteration就需要接近3天的时间，而官方论文的训练总数是整整600K
iteration，这就意味着如果我要跑一次全量训练起码要30天，这肯定是无法接受的，因此需要定位问题再进行性能优化。</p>
<span id="more"></span>
<h1 id="问题定位">1. 问题定位</h1>
<p>PyTorch Profiler是PyTorch
1.8+内置的<strong>全栈性能分析器</strong>，可一键记录<strong>CPU、GPU、内存、数据传输、算子调用栈</strong>等细粒度指标，并直接输出<strong>TensorBoard
可视化</strong>或<strong>Chrome
Trace</strong>文件，帮助快速定位训练/推理瓶颈。</p>
<p>根据官方文档，将训练代码放到以下代码之内：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> profile(</span><br><span class="line">                activities=[torch.profiler.ProfilerActivity.CPU,</span><br><span class="line">                            torch.profiler.ProfilerActivity.CUDA],</span><br><span class="line">                schedule=torch.profiler.schedule(wait=<span class="number">1</span>, warmup=<span class="number">1</span>, active=<span class="number">4</span>, repeat=<span class="number">1</span>),</span><br><span class="line">                on_trace_ready=tensorboard_trace_handler(<span class="string">&quot;./train_log&quot;</span>),</span><br><span class="line">                with_stack=<span class="literal">True</span>,</span><br><span class="line">                profile_memory=<span class="literal">True</span>,</span><br><span class="line">                record_shapes=<span class="literal">False</span>,</span><br><span class="line">        ) <span class="keyword">as</span> prof:</span><br><span class="line">    <span class="comment"># ...训练代码...</span></span><br><span class="line">    prof.step()</span><br><span class="line">    <span class="keyword">if</span> iteration &gt;= <span class="number">1</span> + <span class="number">1</span> + <span class="number">4</span>:</span><br><span class="line">        <span class="keyword">return</span></span><br></pre></td></tr></table></figure>
<p>运行之后就能在同级目录里看到trace.json文件，然后安装tensorboard的profiler插件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install torch_tb_profiler</span><br></pre></td></tr></table></figure>
<p>使用tensorboard打开trace文件：</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensorboard --logdir=./train_log</span><br></pre></td></tr></table></figure>
<p>在面板中可以看到各种操作的时间占比，但是不知道为什么我这里看不到Dataloader的时间占比，即便我按照某issue里面说的把Dataloader的num_workers设置为0，使数据加载发生在主线程里，依然没法解决这个问题。无论如何，从面板可以看出GPU利用率只有11.85%，Kernel操作只占了运行时间的11.3%，性能亟待优化。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/tensorboard.png"></p>
<p>然后我在<a target="_blank" rel="noopener" href="https://docs.pytorch.ac.cn/tutorials/intermediate/tensorboard_profiler_tutorial.html">profiler_tutorial</a>的warning里看到tensorboard和profiler的集成已经弃用了，可以使用<a target="_blank" rel="noopener" href="https://ui.perfetto.dev/">Perfetto
UI</a>来分析trace文件，用其打开trace文件终于能够显示Dataloader的数据了，根据分析结果可以看到在一个iteration中Dataloader的运行时间达到了4s左右，模型的forward方法在900ms左右，backward则在1.4s左右，很明显性能瓶颈在于数据加载，需要针对Dataset类进行优化。</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/perfetto.png"></p>
<h1 id="性能优化">2. 性能优化</h1>
<h2 id="转换为lmdb数据库">2.1 转换为LMDB数据库</h2>
<p>LMDB是一个<strong>高性能、嵌入式键值数据库</strong>，被广泛用于需要<strong>低延迟、高并发读</strong>的场景，LMDB整库就是单个文件，通过
<code>mmap()</code>
一次性映射到进程地址空间，可以减少文件寻址的时间。网上大多博客在谈数据加载优化时首要提到的就是将数据集转换为lmdb格式，故采用如下代码进行转换，在转换时，我把图片转换为了tensor
bytes再进行存储，读取时就可以使用<code>torch.load</code>直接转换为tensor，而不需要再进行图片解码，但是要注意存储的tensor是uint8类型的，如果存储float32则会导致占用空间大大增多，增加的io耗时会多于减少的解码耗时，得不偿失：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, (key, img_path) <span class="keyword">in</span> <span class="built_in">enumerate</span>(tqdm(img_meta, desc=<span class="string">&quot;转换并写入 LMDB&quot;</span>)):</span><br><span class="line">    <span class="keyword">try</span>:</span><br><span class="line">        img = Image.<span class="built_in">open</span>(img_path).convert(<span class="string">&#x27;RGB&#x27;</span>)</span><br><span class="line">        np_img = np.array(img)  <span class="comment"># -&gt; (H, W, C), uint8</span></span><br><span class="line">        tensor = torch.from_numpy(np_img)  <span class="comment"># -&gt; (H, W, C), uint8</span></span><br><span class="line">        tensor = tensor.permute(<span class="number">2</span>, <span class="number">0</span>, <span class="number">1</span>).contiguous()  <span class="comment"># -&gt; (C, H, W), uint8</span></span><br><span class="line">        tensor_bytes = tensor.numpy().tobytes()</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 存入 LMDB</span></span><br><span class="line">        txn.put(key.encode(<span class="string">&#x27;utf-8&#x27;</span>), tensor_bytes)</span><br><span class="line">    <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">f&quot;\n处理文件 <span class="subst">&#123;img_path&#125;</span> 时出错: <span class="subst">&#123;e&#125;</span>&quot;</span>)</span><br><span class="line">        <span class="keyword">continue</span> <span class="comment"># 跳过损坏的文件</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (i + <span class="number">1</span>) % write_frequency == <span class="number">0</span>:</span><br><span class="line">        txn.commit()</span><br><span class="line">        txn = env.begin(write=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">txn.commit()</span><br><span class="line">env.close()</span><br></pre></td></tr></table></figure>
<p>经过测试，LMDB确实加快了数据读取，但是dataloader依旧是瓶颈，还需要进一步优化。torch
profiler的trace可以直观地看出瓶颈在哪，但是要具体到各行代码的耗时分析时就不够好用了，因此下面转用line_profile来进行分析。line_profiler可以给出各行代码的时间占比、执行次数等信息，直接用pip安装即可，然后在Dataset类的<code>__get_item__</code>方法上添加<code>@profile</code>装饰器，使用<code>kernprof -l -v test.py</code>命令来启动一个迭代读取Dataset的代码，最终会在终端里打印各行代码耗时信息，把代码里耗时比较高的挑出来，结果如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Line #      Hits         Time  Per Hit   % Time  Line Contents</span><br><span class="line">==============================================================</span><br><span class="line">   135      3030   11093407.8   3661.2      9.3              hr_img_bytes = self._get_data_from_lmdb(self.img_env, hr_img_key)</span><br><span class="line">   </span><br><span class="line">   139      3030   24507465.6   8088.3     20.5              lr_img = torch.load(io.BytesIO(lr_img_bytes)).float() / 255.0</span><br><span class="line">      </span><br><span class="line">   140      3030   32407331.8  10695.5     27.1              hr_img = torch.load(io.BytesIO(hr_img_bytes)).float() / 255.0</span><br><span class="line">   </span><br><span class="line">   156      3030   12741764.0   4205.2     10.7              hr_depth_bytes = self._get_data_from_lmdb(self.depth_env, hr_depth_key)</span><br></pre></td></tr></table></figure>
<p>行号135的代码用于从LMDB数据库中读取高分辨率图片的bytes数据，行号156则是读取高分辨率图对应的深度图，行号139-140则是将bytes数据转换为低分辨率图片和高分辨率图片，然后转换数据类型并进行归一化。这四行代码的耗时占比基本都在10%以上，存在可优化空间。</p>
<p>同时使用代码从Dataset中读取100个batch，整体耗时达到了119.64s，平均1.2s读取一个batch。</p>
<h2 id="div_">2.2 div_()</h2>
<p>针对<code>lr_img = torch.load(io.BytesIO(lr_img_bytes)).float() / 255.0</code>这行代码，我原以为其瓶颈在于<code>torch.load</code>操作，但是当我把这行代码分为<code>torch.load</code>、<code>lr_img = lr_img.float()</code>和<code>lr_img = lr_img / 255.0</code>时才发现最后这个除法操作的耗时远远大于前两步。</p>
<p>经过调研发现，<code>lr_img = lr_img / 255.0</code>是需要先开辟一块新内存用于存储结果，然后再进行除法操作的，而pytorch中提供了<code>div_()</code>方法来进行原地除法，无需开辟新内存，使用以下代码来比较两者的性能差异：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch, time</span><br><span class="line"></span><br><span class="line">x = torch.randn(<span class="number">3</span>, <span class="number">720</span>, <span class="number">1280</span>, dtype=torch.float32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 1. out-of-place</span></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">t0 = time.time()</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    y = x / <span class="number">255.0</span></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;out-of-place:&quot;</span>, time.time() - t0, <span class="string">&quot;s&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 2. in-place</span></span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line">t0 = time.time()</span><br><span class="line"><span class="keyword">for</span> _ <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">100</span>):</span><br><span class="line">    x.div_(<span class="number">255.0</span>)</span><br><span class="line">torch.cuda.synchronize()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;in-place:&quot;</span>, time.time() - t0, <span class="string">&quot;s&quot;</span>)</span><br></pre></td></tr></table></figure>
<p>最终结果如下，两者性能差距将近21倍：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out-of-place: 0.12485671043395996 s</span><br><span class="line">in-place: 0.005963802337646484 s</span><br></pre></td></tr></table></figure>
<p>再次使用line_profiler进行分析，除法操作的时间占比大幅降低：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">Line #      Hits         Time  Per Hit   % Time  Line Contents</span><br><span class="line">==============================================================</span><br><span class="line">   134      3030    1165666.1    384.7      2.5              lr_img = torch.load(io.BytesIO(lr_img_bytes))</span><br><span class="line">   135      3030    2003618.1    661.3      4.3              hr_img = torch.load(io.BytesIO(hr_img_bytes))</span><br><span class="line"></span><br><span class="line">   138      3030    1288034.8    425.1      2.7              lr_img = lr_img.float()</span><br><span class="line">   139      3030     290921.0     96.0      0.6              lr_img.div_(255.0)</span><br><span class="line">   140      3030    1087394.6    358.9      2.3              hr_img = hr_img.float()</span><br><span class="line">   141      3030     195675.0     64.6      0.4              hr_img.div_(255.0)</span><br></pre></td></tr></table></figure>
<p>再次测试读取100个batch的时间，总共耗时46.88s，提速相当明显。</p>
<h2 id="顺序读">2.3 顺序读</h2>
<p>在原来的<code>__get_item__</code>函数中，对于低分辨率图片和高分辨率图片是交替读取的：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> i, img_path_dict <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_seq):</span><br><span class="line">    lr_img_path = img_path_dict[<span class="string">&quot;lr_img_path&quot;</span>]</span><br><span class="line">    hr_img_path = img_path_dict[<span class="string">&quot;hr_img_path&quot;</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 将绝对路径转换为相对路径作为key</span></span><br><span class="line">    lr_img_key = os.path.relpath(lr_img_path, self.img_root)</span><br><span class="line">    hr_img_key = os.path.relpath(hr_img_path, self.img_root)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 从LMDB获取图片数据</span></span><br><span class="line">    lr_img_bytes = self._get_data_from_lmdb(self.img_env, lr_img_key)</span><br><span class="line">    hr_img_bytes = self._get_data_from_lmdb(self.img_env, hr_img_key)</span><br><span class="line">   	</span><br><span class="line">    <span class="comment"># 加载</span></span><br><span class="line">    lr_img = torch.load(io.BytesIO(lr_img_bytes)).<span class="built_in">float</span>()</span><br><span class="line">    hr_img = torch.load(io.BytesIO(hr_img_bytes)).<span class="built_in">float</span>()</span><br><span class="line">    lr_img.div_(<span class="number">255.0</span>)</span><br><span class="line">    hr_img.div_(<span class="number">255.0</span>)</span><br></pre></td></tr></table></figure>
<p>而前面提到，LMDB是使用B+树来组织数据的，我们都知道，B+树的相邻叶子节点之间存在指针，从而优化了顺序访问的速度，而高分辨率图片和低分辨率图片的key是不一样的，高分辨率的key之间是顺序的，低分辨率的key之间也是顺序的，而上面这种读取一张低分辨率图片又去读取一张高分辨率图片的做法就无法享受到B+树的优化了。</p>
<p>因此我把低分辨率图片和高分辨率图片的读取聚在了一起：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> self.img_env.begin(write=<span class="literal">False</span>) <span class="keyword">as</span> txn:</span><br><span class="line">    <span class="keyword">for</span> i, img_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_seq):</span><br><span class="line">        lr_img_path = img_path[<span class="string">&quot;lr_img_path&quot;</span>]</span><br><span class="line">        lr_img_key = os.path.relpath(lr_img_path, self.img_root)</span><br><span class="line">        lr_img_bytes = txn.get(lr_img_key.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">        lr_img = torch.load(io.BytesIO(lr_img_bytes)).<span class="built_in">float</span>()</span><br><span class="line">        lr_img.div_(<span class="number">255.0</span>)</span><br><span class="line">        lrs.append(lr_img)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i, img_path <span class="keyword">in</span> <span class="built_in">enumerate</span>(img_seq):</span><br><span class="line">        hr_img_path = img_path[<span class="string">&quot;hr_img_path&quot;</span>]</span><br><span class="line">        hr_img_key = os.path.relpath(hr_img_path, self.img_root)</span><br><span class="line">        hr_img_bytes = txn.get(hr_img_key.encode(<span class="string">&#x27;utf-8&#x27;</span>))</span><br><span class="line">        hr_img = torch.load(io.BytesIO(hr_img_bytes)).<span class="built_in">float</span>()</span><br><span class="line">        hr_img.div_(<span class="number">255.0</span>)</span><br><span class="line">        hrs.append(hr_img)</span><br></pre></td></tr></table></figure>
<p>再次测试100个batch读取时间，用时22.056s。</p>
<h1 id="final">3. Final</h1>
<p>除了以上的优化以外，我发现在训练过程中模型并不需要用到高分辨率图的深度图，因此删掉了读取代码，也带了很大的速度提升，不过没什么技术性，在此不赘述。</p>
<p>使用优化后的数据集再跑一次pytorch
profiler分析，最终结果如下图所示：</p>
<p><img class="lazy" src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAEAAAABCAYAAAAfFcSJAAAABGdBTUEAALGPC/xhBQAAADhlWElmTU0AKgAAAAgAAYdpAAQAAAABAAAAGgAAAAAAAqACAAQAAAABAAAAAaADAAQAAAABAAAAAQAAAADa6r/EAAAAC0lEQVQIHWNgAAIAAAUAAY27m/MAAAAASUVORK5CYII=" data-src="/2025/10/16/%E8%AE%B0%E4%B8%80%E6%AC%A1pytorch%20Dataset%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/perfetto2.png"></p>
<p>可以看到相比模型推理和反向传播，数据集加载要短得多。然而跑训练时虽然能够感受到一点提速，但是GPU利用率也仅仅是稳定在50%左右，还不是很理想，目前仍在想办法优化其他部分的代码。</p>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用<a
target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享
4.0 国际</a>许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="body"><div class="item" id="prev"></div><div class="item" id="next"><div class="note">较早文章</div><a href="/2023/11/05/Raft%E7%AE%97%E6%B3%95%E8%AF%A6%E8%A7%A3/">Raft算法详解</a></div></section></div>






  <div class='related-wrap md reveal' id="comments">
    <div class='cmt-title cap theme'>
      快来参与讨论吧
    </div>
    <div class='cmt-body waline'>
      

<div id="waline_container" class="waline_thread"><svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本站由 <a href="/"><span class="citation"
data-cites="Eumendies">@Eumendies</span></a> 使用 <a
target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar">Stellar</a>
主题创建。 本博客所有文章除特别声明外，均采用 <a
target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA
4.0</a> 许可协议，转载请注明出处。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.version = '1.15.1';
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.15.1';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://fastly.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js'
  };

  // stellar js
  stellar.plugins.stellar = Object.assign({"sites":"/js/plugins/sites.js","friends":"/js/plugins/friends.js","ghinfo":"/js/plugins/ghinfo.js","timeline":"/js/plugins/timeline.js","linkcard":"/js/plugins/linkcard.js","fcircle":"/js/plugins/fcircle.js"});

  stellar.plugins.marked = Object.assign("https://cdn.bootcdn.net/ajax/libs/marked/4.0.18/marked.min.js");
  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://fastly.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://fastly.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://fastly.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://fastly.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function load_comment(){
    if(!document.getElementById("waline_container"))return;
    stellar.loadCSS('https://unpkg.com/@waline/client@v2/dist/waline.css');
    stellar.loadScript('https://unpkg.com/@waline/client@v2/dist/waline.js', {defer:true}).then(function () {
      const el = document.getElementById("waline_container");
      var path = el.getAttribute('comment_id');
      if (!path) {
        path = decodeURI(window.location.pathname);
      }
      Waline.init(Object.assign({"js":"https://unpkg.com/@waline/client@v2/dist/waline.js","css":"https://unpkg.com/@waline/client@v2/dist/waline.css","serverURL":"https://waline-blog-self.vercel.app/","commentCount":false,"pageview":false,"emoji":["https://unpkg.com/@waline/emojis@1.1.0/qq","https://unpkg.com/@waline/emojis@1.1.0/tieba","https://gcore.jsdelivr.net/gh/norevi/waline-blobcatemojis@1.0/blobs"],"meta":["昵称","邮箱","nick","mail"],"requiredMeta":["nick"],"lang":"zh-CN","wordLimit":0,"pageSize":10,"locale":{"placeholder":"快来发表你的看法吧（不用登录也能评论）"},"login":"enable"}, {
        el: '#waline_container',
        path: path,
      }));
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
    console.log('DOM fully loaded and parsed');
    load_comment();
  });

</script>




<!-- inject -->


  </div>
</body>
</html>
